## [比赛地址](https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/leaderboard)
**public LB:110**
**private LB:58**
**银牌区**

**关于代码**:大部分代码参考自kaggle code区，建议直接参考[1st的开源](https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/discussion/227128)
## 任务描述
> 住院患者在入院过程中可能会插入导管和管线，如果放置不正确，可能会导致严重的并发症。 据报道，多达3％的患者鼻胃管向呼吸道位置不当，其中40％的患者表现出并发症。 在手术室外插管的成年患者中出现气管错位达到 25％。尽早发现管错位是预防危险并发症（甚至死亡）的关键，现在，成千上万的COVID-19患者需要这些管和管线，这一点就尤其重要。
为了判断导管位置是否放置正确，需要医生根据X-rays判断，这样效率较低，如果能开发出一种机器学习算法根据输入的x-rays图像自动判断，将很有实际应用价值。
## 数据
- 11个类别(可能的导管错误类型)，注意可能同时存在多种错误
- 33.7k训练数据
- 约14k不可见的线上测试数据，可见的测试数据3k
- 有部分训练数据进行了精心标注(导管的位置mask,可用于训练语义分割模型)
- 提交要求，给出测试图片中属于每一个类别的错误分别的概率，评价指标AUC

所以该题目是一个X-rays图片的**多标签分类**问题,需要输出每一个错误的概率。对于多标签分类问题，采取的loss为二分类loss的延拓，[对于一个样本而言，将其看作多个二分类，分别计算交叉熵loss后再求和(平均)](https://blog.csdn.net/qq_22210253/article/details/85222093)即可；Pytorch而言，使用 nn.BCEWithLogitsLoss.

## 我们的解决方案
*只是图像分类吗??*

不同于普通的图像分类，整个比赛有意思的地方在于那给出的部分可用于语义分割的精细标注，虽然只是一小部分数据进行了mask标注，但是足够我们训练一个分割模型或者一个**强监督的教师分类模型**来辅助最后的判别，**我们采取的是强监督的teacher模型，然后接着训练students模型，进一步进行finetune**。这也是几乎所有大金/银牌区队伍的思路，当然看了最后金牌区的分享，发现他们还使用到了语义分割模型来辅助判别，这一点也正是我们队伍和前排队伍的差距所在，没有很好的利用上分割模型。

*何为强监督的教师模型??*

这个名字其实是我自己凭感觉取的，正经学术圈的叫法我不太清楚。试想这样一个场景，在一张背景占比大部分的图像里面，真正对我们的模型判断类别有帮助的区域其实只存在于目标所在那一小部分，如果我们能以某种方式让模型更容易关注到那部分区域，是不是就更容易提升模型效果了？所以对于本次比赛而言，我们利用那小部分精细标注的训练集先训一个teacher模型，注意这里我们首先根据标注将图像中目标(导管)所在区域全部赋为一个显著的像素(比如红色)，将这种经过处理的原图输入给分类模型，这样模型很容易学到真正需要关注的地方的信息（这样认为的加入了很强的先验信息，这也是为什么我称它为强监督的原因）。

*如何训练students模型??*

对于students模型的训练而言，计算的loss不仅仅是BCELoss,而还要加上它和teacher模型的距离，这里让students模型的输出特征去逼近teacher模型的特征，使用的loss为MSELoss.也即回归loss+分类loss，这其实就是一种蒸馏的思想。


## 一些感想和思考
- 虽然通过teacher-students-finetune多阶段训练可以取得银牌的成绩，但是和金牌的差距可能还是在于语义分割模型。前排的开源很多使用到了分割模型，使用大分辨率训练语义分割辅助分类任务开源取得最终结果的巨大提升，队友前期提出训练语义分割模型，但当时我天真的认为数据太少可能无法work，所以把这个方案否了，没想到最后这一点反倒成了关键。

- 多尝试一些最新的SOTA,比如nfnet，朴素的训练单折都能到960+.
- 多逛kaggle 社区，多学习大佬们的思路
- 多思考trick为什么能work，为什么不work,不要一上来就盲目的堆trick